## 实验结果分析总结报告

### 概览：实验设计与环境配置

本次实验旨在对比 Spark 上的不同矩阵乘法实现（基准线、广播优化、2D-Grid、SciPy CSR）与 SystemDS 在不同规模 ($N$) 和稀疏度 ($S$) 下的性能。

- **统一配置**: Executor=2, Cores=2, Memory=12G, Parallelism=24.

------

### I. 常规矩阵乘法（Sparsity = 1.0）分析

#### 1. 核心对比实验（N=10000）

| **实现类型**                      | **脚本文件**              | **Wall Clock Duration (s)** | **Shuffle Read (GB)** | **Executor Run Time (min)** |
| --------------------------------- | ------------------------- | --------------------------- | --------------------- | --------------------------- |
| **SystemDS (Dense)**              | `systemds_runner.py`      | **6.43**                    | **0.00**              | **0.00**                    |
| **Spark - 2D-Grid Vectorized**    | `dense_optimized_grid.py` | 64.81                       | 5.96                  | 3.45                        |
| **Spark - Broadcast Opt**         | `dense_optimized.py`      | 109.60                      | 3.59                  | 5.35                        |
| **Spark - Normal (Shuffle Join)** | `dense_baseline.py`       | 205.94                      | 13.87                 | 11.42                       |

- **结论**: **SystemDS** 在此规模下性能具有压倒性优势，但这是通过内存计算绕过分布式开销实现的。在 Spark 内部实现中，**2D-Grid Vectorized** 策略通过优化分块和数据局部性，将耗时减少到基准线的约 $\frac{1}{3}$。

#### 2. 规模扩展性测试（Scale Test）

| **N**     | **实现类型**        | **Wall Clock Duration (s)** | **耗时增长倍数 (相对于 N=10000)** | **Shuffle Read (GB)** |
| --------- | ------------------- | --------------------------- | --------------------------------- | --------------------- |
| **10000** | **Spark - 2D-Grid** | 64.19                       | -                                 | 5.96                  |
| **20000** | **Spark - 2D-Grid** | 402.01                      | 6.3 倍                            | 23.86                 |
| **20000** | **Spark - Normal**  | 1882.50                     | 9.2 倍                            | 105.27                |
| **20000** | **SystemDS**        | **Error**                   | -                                 | **OutOfMemoryError**  |

- **Spark 扩展性**: 2D-Grid 版本的耗时增长（6.3 倍）优于理论 $O(N^3)$ 复杂度下的 8 倍增长，显示了其良好的可扩展性。
- **SystemDS 局限性**: SystemDS 在 $N \ge 20000$ 时均因 **Java heap space OutOfMemoryError** 失败，证明其高性能的单机模式不适用于处理大规模密集矩阵。

------

### II. 稀疏矩阵乘法（Sparsity $\le 0.5$）分析

#### 1. 核心对比实验（N=10000, S=0.01）

| **实现类型**                   | **脚本文件**              | **Wall Clock Duration (s)** | **Shuffle Read** | **关键优化**        |
| ------------------------------ | ------------------------- | --------------------------- | ---------------- | ------------------- |
| **SystemDS (Sparse)**          | `systemds_runner.py`      | **1.35**                    | **0.00 B**       | 内部优化/单机       |
| **Spark - SciPy CSR**          | `sparse_optimized_csr.py` | 21.37                       | 17.93 MB         | SciPy CSR 格式      |
| **Spark - DataFrame Opt**      | `sparse_optimized_df.py`  | 26.84                       | **2.69 MB**      | DataFrame Broadcast |
| **Spark - Baseline (Shuffle)** | `sparse_baseline.py`      | 1143.53                     | 2.46 GB          | Coordinate Shuffle  |

- **结论**: 引入稀疏矩阵专用格式是性能提升的关键。**SciPy CSR** 和 **DataFrame Opt** 版本将耗时从超千秒的基准线降低到几十秒，提升超过 **40 倍**。

#### 2. 稀疏度敏感度测试（N=10000）

| **Sparsity (S)** | **实现类型**      | **Wall Clock Duration (s)** | **耗时增长倍数 (S=0.01 到 S=0.1)** | **内存瓶颈**                       |
| ---------------- | ----------------- | --------------------------- | ---------------------------------- | ---------------------------------- |
| **0.01**         | **SciPy CSR**     | 22.04                       | -                                  | 无                                 |
| **0.1**          | **SciPy CSR**     | 64.51                       | 2.9 倍                             | 无                                 |
| **0.1**          | **DataFrame Opt** | 456.87                      | **16.5 倍**                        | 敏感                               |
| **0.5**          | **DataFrame Opt** | **Error**                   | -                                  | **Not enough memory to broadcast** |
| **0.5**          | **SystemDS**      | 8.55                        | -                                  | 无                                 |

- **性能稳定性**: **SciPy CSR** 对稀疏度变化具有更强的鲁棒性，S 从 0.01 增至 0.1 时，耗时仅增加 2.9 倍，而 **DataFrame Opt** 暴增 16.5 倍。
- **Broadcast 风险**: DataFrame Broadcast Opt 在 $S=0.5$（半稠密）时失败，报出内存溢出错误，限制了其适用范围。

#### 3. 稀疏矩阵扩展性测试（Scale Test）(S=0.01)

| **N**     | **实现类型**          | **Wall Clock Duration (s)** | **耗时增长倍数 (相对于 N=10000)** |
| --------- | --------------------- | --------------------------- | --------------------------------- |
| **10000** | **Spark - SciPy CSR** | 21.64                       | -                                 |
| **40000** | **Spark - SciPy CSR** | 95.70                       | 4.4 倍                            |
| **40000** | **SystemDS**          | 4.58                        | 3.3 倍                            |

- **优秀的稀疏扩展性**: SciPy CSR 版本的耗时增长（4.4 倍）远优于密集矩阵的 $O(N^3)$ 增长，证明了稀疏算法在大规模稀疏数据上的高效性。

------

### III. 总结：性能特征与优化策略

| **矩阵类型**      | **最佳实现/工具**                                    | **性能特征/适用场景**                                        | **核心优化策略**                                            | **局限性/风险**                                              |
| ----------------- | ---------------------------------------------------- | ------------------------------------------------------------ | ----------------------------------------------------------- | ------------------------------------------------------------ |
| **常规 (Dense)**  | **SystemDS** (小规模) / **Spark - 2D-Grid** (大规模) | SystemDS 在小规模上极致快速。 Spark 2D-Grid 具有良好可扩展性。 | **2D-Grid 分块**优化数据局部性和 Shuffle 成本。             | SystemDS 不适用于 $N \ge 20000$ 的大规模计算（内存溢出）。   |
| **稀疏 (Sparse)** | **SystemDS** (所有规模) / **Spark - SciPy CSR**      | SciPy CSR 性能稳定，扩展性极佳。                             | 采用 **CSR 稀疏存储格式**(Compressed Sparse Row) 进行计算。 | Spark Broadcast 优化不适用于 $S \ge 0.5$ 的半稠密矩阵（内存溢出）。 |

- **SystemDS**: 凭借单机模式和高效的稀疏/密集核心，在 $N \le 10000$ 且无内存瓶颈时，性能最优。
- **Spark**: 在大规模或半稠密场景下，其分布式和容错能力保证了鲁棒性。**2D-Grid** 和 **SciPy CSR** 分别是密集和稀疏计算的最有效优化策略。