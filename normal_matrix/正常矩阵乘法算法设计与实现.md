## 3. 正常矩阵乘法算法设计与实现

本次实验共实现了三个版本的矩阵乘法逻辑：

### 3.1 基准实现：Shuffle Join (Normal)

```python
# normal_mul.py
from pyspark.sql import SparkSession
import numpy as np
import time
import datetime
import urllib.request
import json
import os

"""
zsh 1207
命令：
spark-submit \
  --master spark://master:7077 \
  --num-executors 2 \
  --executor-cores 2 \
  --executor-memory 12G \
  --driver-memory 4G \
  --conf spark.default.parallelism=24 \
  normal_mul.py
"""



# --- 实验参数 (建议 N=4000 或 8000) ---
N = 10000        
BLOCK_SIZE = 1000     
NUM_PARTITIONS = 12   
LOG_FILE = "Normal_mul_results.txt"

spark = SparkSession.builder \
    .appName(f"MatrixMul_Normal_N{N}") \
    .getOrCreate()
sc = spark.sparkContext

def get_application_metrics(sc):
    """抓取 Spark 内部 Shuffle 指标"""
    try:
        app_id = sc.applicationId
        url = f"http://localhost:4040/api/v1/applications/{app_id}/allexecutors"
        req = urllib.request.Request(url)
        with urllib.request.urlopen(req) as response:
            data = json.loads(response.read().decode('utf-8'))
        s_read, s_write = 0, 0
        for executor in data:
            if executor['id'] != 'driver':
                s_read += executor.get('totalShuffleRead', 0)
                s_write += executor.get('totalShuffleWrite', 0)
        return s_read, s_write
    except:
        return 0, 0

def format_bytes(size):
    power = 2**10
    n = 0
    power_labels = {0 : '', 1: 'K', 2: 'M', 3: 'G', 4: 'T'}
    while size > power:
        size /= power
        n += 1
    return f"{size:.2f} {power_labels[n]}B"

def log_result(msg):
    print(msg)
    with open(LOG_FILE, "a") as f:
        f.write(f"[{datetime.datetime.now()}] {msg}\n")

# --- 业务逻辑 ---
def generate_block_matrix(rows, cols, block_size, num_partitions):
    r_blocks = (rows + block_size - 1) // block_size
    c_blocks = (cols + block_size - 1) // block_size
    seeds = []
    for i in range(r_blocks):
        for j in range(c_blocks):
            cur_rows = block_size if (i+1)*block_size <= rows else rows - i*block_size
            cur_cols = block_size if (j+1)*block_size <= cols else cols - j*block_size
            seeds.append(((i, j), (cur_rows, cur_cols)))
    return sc.parallelize(seeds, num_partitions).map(
        lambda x: (x[0], np.random.rand(x[1][0], x[1][1]))
    )

def block_multiply(iter_data):
    for item in iter_data:
        block_k, ( (block_i, mat_A), (block_j, mat_B) ) = item
        yield ((block_i, block_j), np.dot(mat_A, mat_B))

try:
    log_result("="*50)
    log_result(f"Type: Normal (Shuffle Join) | N: {N} | Block: {BLOCK_SIZE}")
    start_time = time.time()

    mat_A = generate_block_matrix(N, N, BLOCK_SIZE, NUM_PARTITIONS)
    mat_B = generate_block_matrix(N, N, BLOCK_SIZE, NUM_PARTITIONS)

    A_keyed = mat_A.map(lambda x: (x[0][1], (x[0][0], x[1])))
    B_keyed = mat_B.map(lambda x: (x[0][0], (x[0][1], x[1])))

    # 这里的 join 会触发 Shuffle
    result_rdd = A_keyed.join(B_keyed).mapPartitions(block_multiply).reduceByKey(lambda m1, m2: m1 + m2)
    count = result_rdd.count()

    end_time = time.time()
    s_read, s_write = get_application_metrics(sc)

    log_result(f"Status: Success | Blocks: {count}")
    log_result(f"Duration: {end_time - start_time:.4f} s")
    log_result(f"Shuffle Read:  {format_bytes(s_read)}")
    log_result(f"Shuffle Write: {format_bytes(s_write)}")

except Exception as e:
    log_result(f"Error: {str(e)}")
finally:
    spark.stop()
```

- **核心逻辑**：基于 `Reduce-Side Join`。
- **实现细节**：
  1. 将矩阵 $A$ 和 $B$ 切分为 $N \times N$ 的块。
  2. 变换 Key：$A$ 块以列号 $k$ 为 Key，$B$ 块以行号 $k$ 为 Key。
  3. 执行 `A.join(B)`，将所有需要相乘的块通过网络 Shuffle 到同一节点。
  4. 执行本地乘法后通过 `reduceByKey` 聚合。
- **预期缺陷**：`join` 操作会导致全量数据的 Shuffle，网络 I/O 开销巨大。

### 3.2 优化实现：Broadcast Map-Side Join (Optimized)

```python
# optimized_mul.py
from pyspark.sql import SparkSession
import numpy as np
import time
import datetime
import urllib.request
import json

"""
zsh 1207
命令：
spark-submit \
  --master spark://master:7077 \
  --num-executors 2 \
  --executor-cores 2 \
  --executor-memory 12G \
  --driver-memory 4G \
  optimized_mul.py

"""


# --- 实验参数 (保持与 Normal 一致) ---
N = 10000          
BLOCK_SIZE = 1000     
NUM_PARTITIONS = 12 
LOG_FILE = "optimized_mul_results.txt"

spark = SparkSession.builder.appName(f"MatrixMul_Optimized_N{N}").getOrCreate()
sc = spark.sparkContext

# --- 工具函数 (保持一致) ---
def get_application_metrics(sc):
    try:
        app_id = sc.applicationId
        url = f"http://localhost:4040/api/v1/applications/{app_id}/allexecutors"
        req = urllib.request.Request(url)
        with urllib.request.urlopen(req) as response:
            data = json.loads(response.read().decode('utf-8'))
        s_read, s_write = 0, 0
        for executor in data:
            if executor['id'] != 'driver':
                s_read += executor.get('totalShuffleRead', 0)
                s_write += executor.get('totalShuffleWrite', 0)
        return s_read, s_write
    except: return 0, 0

def format_bytes(size):
    power = 2**10
    n = 0
    power_labels = {0 : '', 1: 'K', 2: 'M', 3: 'G', 4: 'T'}
    while size > power: size /= power; n += 1
    return f"{size:.2f} {power_labels[n]}B"

def log_result(msg):
    print(msg)
    with open(LOG_FILE, "a") as f:
        f.write(f"[{datetime.datetime.now()}] {msg}\n")

# --- 业务逻辑 ---
def generate_block_matrix(rows, cols, block_size, num_partitions):
    r_blocks = (rows + block_size - 1) // block_size
    c_blocks = (cols + block_size - 1) // block_size
    seeds = []
    for i in range(r_blocks):
        for j in range(c_blocks):
            cur_rows = block_size if (i+1)*block_size <= rows else rows - i*block_size
            cur_cols = block_size if (j+1)*block_size <= cols else cols - j*block_size
            seeds.append(((i, j), (cur_rows, cur_cols)))
    return sc.parallelize(seeds, num_partitions).map(
        lambda x: (x[0], np.random.rand(x[1][0], x[1][1]))
    )

try:
    log_result("="*50)
    log_result(f"Type: Optimized (Broadcast) | N: {N} | Block: {BLOCK_SIZE}")
    start_time = time.time()

    mat_A = generate_block_matrix(N, N, BLOCK_SIZE, NUM_PARTITIONS)
    mat_B_rdd = generate_block_matrix(N, N, BLOCK_SIZE, NUM_PARTITIONS)

    # 核心优化：广播 B
    B_local = mat_B_rdd.collect() 
    B_dict = {key: matrix for key, matrix in B_local}
    B_broadcast = sc.broadcast(B_dict)

    def broadcast_multiply(block_A_tuple):
        (block_i, block_k), mat_A_sub = block_A_tuple
        full_B = B_broadcast.value
        relevant_B_keys = [key for key in full_B.keys() if key[0] == block_k]
        results = []
        for b_key in relevant_B_keys:
            block_j = b_key[1]
            results.append( ((block_i, block_j), np.dot(mat_A_sub, full_B[b_key])) )
        return results

    result_rdd = mat_A.flatMap(broadcast_multiply).reduceByKey(lambda m1, m2: m1 + m2)
    count = result_rdd.count()

    end_time = time.time()
    s_read, s_write = get_application_metrics(sc)

    log_result(f"Status: Success | Blocks: {count}")
    log_result(f"Duration: {end_time - start_time:.4f} s")
    log_result(f"Shuffle Read:  {format_bytes(s_read)}")
    log_result(f"Shuffle Write: {format_bytes(s_write)}")

except Exception as e:
    log_result(f"Error: {str(e)}")
finally:
    spark.stop()
```

- **核心逻辑**：基于 `Map-Side Join`。
- **实现细节**：
  1. 利用 Worker 节点内存充裕的特点，将较小的矩阵（或同等大小的 $B$ 矩阵）通过 `sc.broadcast` 广播到所有 Executor。
  2. 取消 `join` 操作，直接在 Map 阶段遍历 $A$ 的分块，从广播变量中获取对应的 $B$ 块进行计算。
  3. 仅在最终结果聚合阶段（`reduceByKey`）产生少量 Shuffle。
- **预期优势**：消除了数据准备阶段的 Shuffle，理论性能显著提升。

## 4. 实验结果数据

SystemDS 代码

```python
# systemds_mul.py
from pyspark.sql import SparkSession
from systemds.context import SystemDSContext
import time
import datetime
import urllib.request
import json

"""
zsh 1207
命令：
spark-submit \
  --master spark://master:7077 \
  --num-executors 2 \
  --executor-cores 2 \
  --executor-memory 12G \
  --driver-memory 1G \
  systemds_mul.py
"""


# --- 实验参数 (必须足够大以触发分布式) ---
N = 10000 
LOG_FILE = "Systemds_mul_results.txt"

spark = SparkSession.builder.appName("SystemDS_MatrixMul").getOrCreate()
sc = spark.sparkContext
sds = SystemDSContext() # 自动获取 Spark Context

# --- 工具函数 ---
def get_application_metrics(sc):
    try:
        app_id = sc.applicationId
        url = f"http://localhost:4040/api/v1/applications/{app_id}/allexecutors"
        req = urllib.request.Request(url)
        with urllib.request.urlopen(req) as response:
            data = json.loads(response.read().decode('utf-8'))
        s_read, s_write = 0, 0
        for executor in data:
            if executor['id'] != 'driver':
                s_read += executor.get('totalShuffleRead', 0)
                s_write += executor.get('totalShuffleWrite', 0)
        return s_read, s_write
    except: return 0, 0

def format_bytes(size):
    power = 2**10
    n = 0
    power_labels = {0 : '', 1: 'K', 2: 'M', 3: 'G', 4: 'T'}
    while size > power: size /= power; n += 1
    return f"{size:.2f} {power_labels[n]}B"

def log_result(msg):
    print(msg)
    with open(LOG_FILE, "a") as f:
        f.write(f"[{datetime.datetime.now()}] {msg}\n")

try:
    log_result("="*50)
    log_result(f"Type: SystemDS (Distributed Force) | N: {N}")
    
    # 业务逻辑
    X = sds.rand(rows=N, cols=N, min=0.0, max=1.0, pdf="uniform", sparsity=1.0)
    Y = sds.rand(rows=N, cols=N, min=0.0, max=1.0, pdf="uniform", sparsity=1.0)
    res = (X @ Y).sum()

    log_result("Starting execution...")
    start_time = time.time()
    final_value = res.compute(verbose=True) # 触发计算
    end_time = time.time()

    s_read, s_write = get_application_metrics(sc)

    log_result(f"Status: Success")
    log_result(f"Duration: {end_time - start_time:.4f} s")
    log_result(f"Shuffle Read:  {format_bytes(s_read)}")
    log_result(f"Shuffle Write: {format_bytes(s_write)}")

except Exception as e:
    log_result(f"Error: {str(e)}")
finally:
    sds.close()
    spark.stop()
```

**实验统一参数**：

- **矩阵规模 (N)**：$10000 \times 10000$ (Double Precision, 约 800MB)
- **分块大小 (Block Size)**：$1000 \times 1000$ (Normal/Optimized)

| **实验组别**  | **核心策略**   | **总耗时 (Time)** | **Shuffle Read** | **Shuffle Write** | **相对性能**    |
| ------------- | -------------- | ----------------- | ---------------- | ----------------- | --------------- |
| **Normal**    | Shuffle Join   | **208.7 s**       | **8.95 GB**      | **8.95 GB**       | 1.0x (Baseline) |
| **Optimized** | Broadcast      | **98.4 s**        | **1.42 GB**      | **1.42 GB**       | **2.1x**        |
| **SystemDS**  | Hybrid Runtime | **7.6 s**         | **0.00 B**       | **0.00 B**        | **27.4x**       |
|               |                |                   |                  |                   |                 |

## 5. 性能对比与深度分析

### 5.1 Shuffle 对性能的决定性影响

- Normal 组 (8.95 GB)：

  数据表明，基于 Join 的实现产生了巨大的网络开销。结果矩阵本身仅约 800MB，但 Shuffle 量高达 8.95GB，这意味着数据在网络中产生了超过 10倍的冗余传输。这是导致耗时最长（208s）的直接原因。

- Optimized 组 (1.42 GB)：

  通过引入广播变量，我们成功消除了 $A$ 和 $B$ 在计算前的混洗。剩余的 1.42 GB Shuffle 仅来自于最终结果子块的聚合（reduceByKey）。这一策略直接减少了 84% 的网络传输，使性能提升了 2 倍。

### 5.2 SystemDS 的“降维打击”

SystemDS 在本实验中跑出了惊人的 **7.6秒** 且 **0 Shuffle**。

- **原因分析**：SystemDS 具备 **混合运行时 (Hybrid Runtime)** 机制。虽然矩阵为 $10000 \times 10000$，但在 Driver 拥有 4GB 内存的情况下，SystemDS 的编译器（Compiler）智能判断该任务无需分布式处理，直接降级为 **CP (Control Program)** 模式，在单机内存中利用底层 C++/Java 库完成计算。
- **启示**：分布式系统并非总是最优解。在数据规模未突破单机瓶颈时，消除分布式调度的 Overhead 才是提升性能的关键。